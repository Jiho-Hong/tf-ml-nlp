{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# word2vec를 활용한 모델 구현"
      ],
      "metadata": {
        "id": "LFrZkmXmkbWk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 전처리된 텍스트 데이터 불러오기 및 각 단어의 리스트 나누기"
      ],
      "metadata": {
        "id": "Yji9rIPfknEz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rgutDF20kTmy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "DATA_IN_PATH = './data_in/'\n",
        "TRAIN_CLEAN_DATA = 'train_clean.csv'\n",
        "\n",
        "train_data = pd.read_csv(DATA_IN_PATH + TRAIN_CLEAN_DATA)\n",
        "\n",
        "reviews = list(train_data['review'])\n",
        "sentiments = list(train_data['sentiment'])\n",
        "\n",
        "sentences = []\n",
        "for review in reviews:\n",
        "    sentences.append(review.split())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 하이퍼파라미터 설정"
      ],
      "metadata": {
        "id": "t1F1wvnel4zR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_features = 300 # 워드 벡터 특징값 수\n",
        "min_word_count = 40 # 단어에 대한 최소 빈도 수\n",
        "num_workers = 4 # 프로세스 개수\n",
        "context = 10 # 컨텍스트 윈도 크기\n",
        "downsampling = 1e-3 # 다운 샘플링 비율"
      ],
      "metadata": {
        "id": "yi8kLkPtlsAh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## gensim 라이브러리 설치"
      ],
      "metadata": {
        "id": "WM6geYLkmYye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rjqr9HwkmfbL",
        "outputId": "1b660cba-af52-48b1-8443-7ce0e1b672ea"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.8/dist-packages (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.21.6)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.8/dist-packages (from gensim) (5.2.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.7.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 진행 상황 확인을 위한 logging"
      ],
      "metadata": {
        "id": "K_AMMIBCmloz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ],
      "metadata": {
        "id": "uo4z0RGKmhgd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 학습"
      ],
      "metadata": {
        "id": "bcRkAaDFnDpt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import word2vec\n",
        "\n",
        "model = word2vec.Word2Vec(sentences, workers=num_workers, \\\n",
        "           size=num_features, min_count = min_word_count, \\\n",
        "            window = context, sample = downsampling)"
      ],
      "metadata": {
        "id": "vI_j9CoSmtex"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 저장"
      ],
      "metadata": {
        "id": "rv8LKnyQns0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"300features_40minwords_10context\"\n",
        "model.save(model_name)"
      ],
      "metadata": {
        "id": "NmjgFHZpnRcR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 하나의 리뷰에 대해 전체 단어의 평균값을 계산하는 함수"
      ],
      "metadata": {
        "id": "n0lGxnS4oRv4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_features(words, model, num_features):\n",
        "    # 출력 벡터 초기화\n",
        "    feature_vector = np.zeros((num_features),dtype=np.float32)\n",
        "\n",
        "    num_words = 0\n",
        "    # 어휘사전 준비\n",
        "    index2word_set = set(model.wv.index2word)\n",
        "\n",
        "    for w in words:\n",
        "        if w in index2word_set:\n",
        "            num_words += 1\n",
        "            # 사전에 해당하는 단어에 대해 단어 벡터를 더함\n",
        "            feature_vector = np.add(feature_vector, model[w])\n",
        "    # 문장의 단어 수만큼 나누어 단어 벡터의 평균값을 문장 벡터로 함\n",
        "    feature_vector = np.divide(feature_vector, num_words)\n",
        "    return feature_vector"
      ],
      "metadata": {
        "id": "WdULMMzHn1ZD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 전체 리뷰에 대해 각 리뷰의 평균 벡터를 구하는 함수"
      ],
      "metadata": {
        "id": "94JDhkuGpIYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset(reviews, model, num_features):\n",
        "    dataset = list()\n",
        "\n",
        "    for s in reviews:\n",
        "        dataset.append(get_features(s, model, num_features))\n",
        "\n",
        "    reviewFeatureVecs = np.stack(dataset)\n",
        "    \n",
        "    return reviewFeatureVecs"
      ],
      "metadata": {
        "id": "S12e4KJOo4YT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 실제 학습에 사용될 입력값"
      ],
      "metadata": {
        "id": "f_W9xQ67pa2I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_vecs = get_dataset(sentences, model, num_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3282UwkpaF6",
        "outputId": "f777d2ad-09aa-4508-a402-192d5f387372"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-52c0d11dc7c6>:15: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  feature_vector = np.add(feature_vector, model[w])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 학습과 검증 데이터셋 분리"
      ],
      "metadata": {
        "id": "YoH08Pu5pgdO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "X = test_data_vecs\n",
        "y = np.array(sentiments)\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "TEST_SPLIT = 0.2\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SPLIT, random_state=RANDOM_SEED)"
      ],
      "metadata": {
        "id": "ANN1CptapfCY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 선언 및 학습"
      ],
      "metadata": {
        "id": "KL2kN6m2punZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lgs = LogisticRegression(class_weight='balanced', max_iter=500)\n",
        "lgs.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57uCCOwGpr7F",
        "outputId": "be31bbf1-b0cb-4165-9d82-8aea2f42627f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(class_weight='balanced', max_iter=500)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 검증 데이터셋을 이용한 성능 평가"
      ],
      "metadata": {
        "id": "Ait9cWt2qW17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy: %f\" % lgs.score(X_test, y_test)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GUYheRHp23g",
        "outputId": "db506a19-65d1-41d0-d785-6d5431b3006d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.866400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 전처리한 평가 데이터를 불러온 후 리뷰 값을 리스트로 저장"
      ],
      "metadata": {
        "id": "_9Z-0W2Sqis1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TEST_CLEAN_DATA = 'test_clean.csv'\n",
        "\n",
        "test_data = pd.read_csv(DATA_IN_PATH + TEST_CLEAN_DATA)\n",
        "\n",
        "test_review = list(test_data['review'])"
      ],
      "metadata": {
        "id": "auqjmg5DqeF2"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 평가 데이터를 각 단어의 리스트로 저장"
      ],
      "metadata": {
        "id": "jhkCOUC9q1Mj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentences = list()\n",
        "for review in test_review:\n",
        "    test_sentences.append(review.split())"
      ],
      "metadata": {
        "id": "cCg3W7fhq-ZY"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 각 단어를 벡터로 만들어 각 리뷰에 대한 특징값 저장"
      ],
      "metadata": {
        "id": "QgUSbo31rJ6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_vecs = get_dataset(test_sentences, model, num_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfZdKqosrQrL",
        "outputId": "36a5f996-1f2f-4314-db90-4b20f8e2bc0a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-52c0d11dc7c6>:15: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  feature_vector = np.add(feature_vector, model[w])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CSV 파일로 만들어 저장"
      ],
      "metadata": {
        "id": "8Nr9-mKyrZDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "DATA_OUT_PATH = './data_out/'\n",
        "\n",
        "test_predicted = lgs.predict(test_data_vecs)\n",
        "\n",
        "if not os.path.exists(DATA_OUT_PATH):\n",
        "    os.makedirs(DATA_OUT_PATH)\n",
        "    \n",
        "ids = list(test_data['id'])\n",
        "answer_dataset = pd.DataFrame({'id': ids, 'sentiment': test_predicted})\n",
        "answer_dataset.to_csv(DATA_OUT_PATH + 'lgs_w2v_answer.csv', index=False, quoting=3)"
      ],
      "metadata": {
        "id": "LXNWQBNwrS4F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}